# 운영 및 모니터링

## 1. 구조화된 로깅 전략

### 1.1 로그 레벨 기준

| 레벨 | 기준 | 예시 |
|------|------|------|
| **ERROR** | 시스템 장애, 즉각 대응 필요 | Agent 프로세스 비정상 종료, DB 연결 실패, Git clone 실패, WorkTree 생성 실패 |
| **WARN** | 재시도 필요하거나 잠재적 문제 | MCP 서버 연결 타임아웃 후 재시도, Checkpoint rollback 실패, 디스크 용량 임계값 초과 |
| **INFO** | 상태 전이, 비즈니스 이벤트 | Workflow 상태 변경(CREATED→RUNNING), Work 시작/완료, Task Query 전송/응답, Report 생성 완료 |
| **DEBUG** | 상세 실행 흐름, 디버깅용 | 이벤트 핸들러 진입/완료, MCP 설정 병합 결과, symlink 생성 경로, Git 명령 실행 상세 |

### 1.2 로그 포맷 (JSON Structured Logging)

모든 로그는 JSON 형식으로 출력한다. 로그 수집 시스템(ELK, Loki 등)과의 통합을 위해 필드를 표준화한다.

```json
{
  "timestamp": "2026-02-03T09:15:30.123Z",
  "level": "INFO",
  "correlationId": "wf-abc123-evt-001",
  "workflowId": "wf-abc123",
  "workId": "wk-def456",
  "taskId": null,
  "event": "WorkflowStatusChanged",
  "message": "Workflow 상태 전이: READY → RUNNING",
  "context": {
    "previousStatus": "READY",
    "newStatus": "RUNNING",
    "workCount": 3
  },
  "duration": null,
  "service": "workflow-orchestrator",
  "hostname": "prod-node-01"
}
```

**필수 필드 정의**

| 필드 | 타입 | 설명 |
|------|------|------|
| `timestamp` | `string (ISO 8601)` | 로그 발생 시각 |
| `level` | `string` | 로그 레벨 (ERROR, WARN, INFO, DEBUG) |
| `correlationId` | `string` | 이벤트 체인 추적 ID |
| `workflowId` | `string \| null` | 관련 Workflow ID |
| `workId` | `string \| null` | 관련 Work ID |
| `taskId` | `string \| null` | 관련 Task ID |
| `event` | `string` | 도메인 이벤트 또는 액션 이름 |
| `message` | `string` | 사람이 읽을 수 있는 설명 |
| `context` | `object` | 추가 구조화된 데이터 |
| `duration` | `number \| null` | 작업 소요 시간 (ms) |
| `service` | `string` | 서비스 식별자 |
| `hostname` | `string` | 호스트명 |

### 1.3 correlationId 기반 이벤트 체인 추적

Workflow 실행 시 하나의 `correlationId`를 생성하고, 해당 Workflow에서 파생되는 모든 이벤트와 로그에 전파한다. 이를 통해 `WorkflowStarted → WorkStarted → QuerySent → QueryResponded → ReportGenerated → WorkCompleted → CheckpointCreated → WorkflowCompleted` 전체 체인을 단일 ID로 추적할 수 있다.

```mermaid
graph LR
    A[WorkflowStarted<br/>correlationId: wf-abc-001] --> B[WorkStarted<br/>correlationId: wf-abc-001]
    B --> C[QuerySent<br/>correlationId: wf-abc-001]
    C --> D[QueryResponded<br/>correlationId: wf-abc-001]
    D --> E[ReportGenerated<br/>correlationId: wf-abc-001]
    E --> F[WorkCompleted<br/>correlationId: wf-abc-001]
    F --> G[CheckpointCreated<br/>correlationId: wf-abc-001]
    G --> H[WorkflowCompleted<br/>correlationId: wf-abc-001]
```

**전파 규칙**
- UseCase 진입 시 `correlationId`를 생성하거나 기존 값을 수신
- EventPublisher가 이벤트 발행 시 현재 컨텍스트의 `correlationId`를 이벤트에 포함
- Event Handler가 이벤트 수신 시 `correlationId`를 컨텍스트에 복원
- Agent 프로세스에 Query 전송 시 `correlationId`를 메타데이터로 전달

### 1.4 민감 정보 마스킹

로그에 민감 정보가 노출되지 않도록 마스킹 처리한다.

| 대상 | 마스킹 규칙 | 예시 |
|------|-----------|------|
| MCP 서버 env 변수 값 | 값 전체 마스킹 | `"OPENAI_API_KEY": "***"` |
| Git URL 인증 토큰 | 토큰 부분 마스킹 | `https://***@github.com/org/repo.git` |
| Agent API 키 | 앞 4자리만 노출 | `sk-ab**...****` |
| McpServerRef envOverrides | 값 전체 마스킹 | `"DB_PASSWORD": "***"` |
| Agent Query 내용 | DEBUG 레벨에서만 전체 출력 | INFO에서는 `"query": "[length=1024]"` |

**구현 방식**: 로그 미들웨어에서 JSON serialization 전 마스킹 함수를 적용한다. 마스킹 대상 필드 목록은 설정 파일에서 관리한다.

```typescript
// 마스킹 대상 패턴
const SENSITIVE_PATTERNS = [
  /env\./i, /token/i, /secret/i, /password/i, /key/i, /credential/i
];
```

---

## 2. 메트릭 수집

### 2.1 Workflow 메트릭

| 메트릭명 | 타입 | 설명 | 알람 임계값 |
|---------|------|------|-----------|
| `workflow.execution.duration` | Histogram | Workflow 전체 실행 시간 (ms) | p95 > 30분 |
| `workflow.status.count` | Gauge | 상태별 Workflow 개수 (RUNNING, PAUSED, FAILED 등) | FAILED > 5 |
| `workflow.success.rate` | Gauge | 완료 성공률 (COMPLETED / 전체 종료) | < 80% |
| `workflow.created.total` | Counter | 누적 생성 수 | — |
| `workflow.completed.total` | Counter | 누적 완료 수 | — |
| `workflow.failed.total` | Counter | 누적 실패 수 | 5분 간 > 3 |
| `workflow.concurrent.running` | Gauge | 현재 동시 실행 중인 Workflow 수 | > 10 |

### 2.2 Agent 메트릭

| 메트릭명 | 타입 | 설명 | 알람 임계값 |
|---------|------|------|-----------|
| `agent.response.duration` | Histogram | Agent Query 응답 시간 (ms) | p95 > 5분 |
| `agent.error.rate` | Gauge | Agent 에러 비율 | > 10% |
| `agent.concurrent.count` | Gauge | 동시 실행 중인 Agent 프로세스 수 | > 20 |
| `agent.start.duration` | Histogram | Agent 프로세스 시작 소요 시간 (ms) | p95 > 30초 |
| `agent.error.total` | Counter | 누적 Agent 에러 수 | 5분 간 > 5 |
| `agent.query.total` | Counter | 누적 Query 전송 수 | — |

### 2.3 Resource 메트릭

| 메트릭명 | 타입 | 설명 | 알람 임계값 |
|---------|------|------|-----------|
| `worktree.active.count` | Gauge | 활성 WorkTree 수 | > 50 |
| `worktree.disk.usage.bytes` | Gauge | WorkTree 전체 디스크 사용량 | > 50GB |
| `worktree.creation.duration` | Histogram | WorkTree 생성 소요 시간 (ms) | p95 > 60초 |
| `report.file.count` | Gauge | 전체 Report 파일 수 | > 1000 |
| `report.disk.usage.bytes` | Gauge | Report 전체 디스크 사용량 | > 5GB |
| `workspace.active.count` | Gauge | 활성 WorkSpace 수 | > 100 |
| `checkpoint.count` | Gauge | 전체 Checkpoint 수 | > 500 |
| `checkpoint.invalid.count` | Gauge | 무효화된 Checkpoint 수 | > 200 |

### 2.4 System 메트릭

| 메트릭명 | 타입 | 설명 | 알람 임계값 |
|---------|------|------|-----------|
| `event.processing.delay` | Histogram | 이벤트 발행~처리 지연 시간 (ms) | p95 > 5초 |
| `event.queue.depth` | Gauge | 미처리 이벤트 큐 깊이 | > 100 |
| `event.published.total` | Counter | 누적 이벤트 발행 수 | — |
| `event.handler.error.total` | Counter | Event Handler 에러 누적 수 | 5분 간 > 3 |
| `mcp.connection.active` | Gauge | 활성 MCP 서버 연결 수 | — |
| `mcp.validation.failure.total` | Counter | MCP 연결 검증 실패 누적 수 | 5분 간 > 5 |
| `db.query.duration` | Histogram | DB 쿼리 응답 시간 (ms) | p95 > 1초 |
| `db.connection.pool.active` | Gauge | DB 커넥션 풀 사용 중 수 | > pool_size * 0.8 |
| `git.command.duration` | Histogram | Git CLI 명령 실행 시간 (ms) | p95 > 30초 |

### 2.5 메트릭 수집 아키텍처

```mermaid
graph LR
    subgraph "Application"
        APP[Workflow Orchestrator] -->|expose| PROM_EP[/metrics endpoint]
    end

    subgraph "Collection"
        PROM[Prometheus] -->|scrape| PROM_EP
    end

    subgraph "Visualization"
        PROM --> GRAF[Grafana Dashboard]
        PROM --> ALERT[Alertmanager]
    end

    ALERT --> SLACK[Slack]
    ALERT --> PAGER[PagerDuty]
```

---

## 3. 분산 트레이싱

### 3.1 OpenTelemetry 기반 트레이싱

Workflow 실행의 전체 이벤트 체인을 하나의 Trace로 추적한다. OpenTelemetry SDK를 사용하여 각 단계를 Span으로 구성한다.

```mermaid
gantt
    title Workflow Trace 예시 (Span 구성)
    dateFormat X
    axisFormat %s

    section Workflow
    workflow.execute           :0, 120

    section Work-0
    work.execute               :0, 60
    agent.start                :0, 5
    task[0].execute            :5, 35
    task[0].query.send         :5, 8
    task[0].query.response     :8, 25
    task[0].report.generate    :25, 35
    task[1].execute            :35, 55
    task[1].query.send         :35, 38
    task[1].query.response     :38, 55
    checkpoint.create          :55, 60

    section Work-1
    work.execute               :60, 120
    agent.start                :60, 65
    task[0].execute            :65, 115
    task[0].query.send         :65, 68
    task[0].query.response     :68, 115
    checkpoint.create          :115, 120
```

### 3.2 Span 계층 구조

```
Trace: workflow.execute (workflowId)
├── Span: work.execute (workId, sequence=0)
│   ├── Span: resource.prepare_workspace (workSpaceId)
│   │   ├── Span: filesystem.create_directory
│   │   └── Span: filesystem.create_symlink (반복)
│   ├── Span: agent.start (model, mcpServerCount)
│   │   └── Span: mcp.config.merge (globalRefs, workRefs)
│   ├── Span: task.execute (taskId, order=0)
│   │   ├── Span: query.send (queryLength)
│   │   ├── Span: query.wait_response
│   │   └── Span: report.generate (reportId, outline)
│   ├── Span: task.execute (taskId, order=1)
│   │   ├── Span: query.send
│   │   └── Span: query.wait_response
│   ├── Span: agent.stop
│   └── Span: checkpoint.create (commitHashes)
│       └── Span: git.commit (반복, gitId별)
├── Span: work.execute (workId, sequence=1)
│   └── ... (동일 구조)
└── Span: resource.cleanup (완료/취소 시)
```

### 3.3 Span Attribute 표준

| Attribute | 설명 | 예시 |
|-----------|------|------|
| `workflow.id` | Workflow 식별자 | `wf-abc123` |
| `workflow.status` | 현재 상태 | `RUNNING` |
| `work.id` | Work 식별자 | `wk-def456` |
| `work.sequence` | 실행 순서 | `0` |
| `work.model` | Agent 모델 | `claude-sonnet-4-20250514` |
| `task.id` | Task 식별자 | `tk-ghi789` |
| `task.order` | Task 순서 | `0` |
| `agent.process.pid` | Agent 프로세스 PID | `12345` |
| `git.id` | Git 식별자 | `git-xyz` |
| `mcp.server.count` | MCP 서버 수 | `3` |
| `error.type` | 에러 유형 | `AgentError` |
| `error.message` | 에러 메시지 | `Process exited with code 1` |

### 3.4 Trace 전파 설정

```typescript
// OpenTelemetry 초기화 예시
import { NodeSDK } from '@opentelemetry/sdk-node';
import { OTLPTraceExporter } from '@opentelemetry/exporter-trace-otlp-http';

const sdk = new NodeSDK({
  traceExporter: new OTLPTraceExporter({
    url: process.env.OTEL_EXPORTER_OTLP_ENDPOINT,
  }),
  instrumentations: [/* http, express, prisma 등 */],
  resource: new Resource({
    [ATTR_SERVICE_NAME]: 'workflow-orchestrator',
    [ATTR_SERVICE_VERSION]: process.env.APP_VERSION,
  }),
});
```

---

## 4. 헬스 체크

### 4.1 엔드포인트 설계

| 엔드포인트 | 용도 | 응답 코드 |
|-----------|------|----------|
| `GET /health` | Liveness probe. 프로세스 생존 확인 | 200: 정상, 503: 비정상 |
| `GET /ready` | Readiness probe. 트래픽 수신 가능 여부 | 200: 준비 완료, 503: 준비 중 |

### 4.2 /health 응답

프로세스가 살아있고 기본 기능이 동작하는지 확인한다. 외부 의존성 장애로 인해 liveness가 실패하지 않도록 최소한의 검사만 수행한다.

```json
{
  "status": "UP",
  "timestamp": "2026-02-03T09:15:30.123Z",
  "uptime": 86400,
  "version": "1.2.0"
}
```

### 4.3 /ready 응답

모든 외부 의존성의 연결 상태를 확인한다. 하나라도 DOWN이면 503을 반환하여 로드밸런서가 트래픽을 전달하지 않도록 한다.

```json
{
  "status": "UP",
  "timestamp": "2026-02-03T09:15:30.123Z",
  "checks": {
    "database": {
      "status": "UP",
      "responseTime": 12
    },
    "gitClient": {
      "status": "UP",
      "responseTime": 45,
      "detail": "git version 2.43.0"
    },
    "mcpServers": {
      "status": "UP",
      "activeConnections": 3,
      "detail": "3/3 servers reachable"
    },
    "eventBus": {
      "status": "UP",
      "queueDepth": 5,
      "responseTime": 3
    },
    "fileSystem": {
      "status": "UP",
      "worktreeRoot": {
        "available": true,
        "freeSpaceGB": 45.2
      },
      "workflowRoot": {
        "available": true,
        "freeSpaceGB": 45.2
      }
    }
  }
}
```

### 4.4 의존성별 체크 상세

| 의존성 | 체크 방법 | 타임아웃 | 실패 시 영향 |
|--------|---------|---------|------------|
| **Database** | `SELECT 1` 쿼리 실행 | 3초 | 전체 서비스 불가 |
| **Git CLI** | `git --version` 실행 | 5초 | Workflow 시작/리소스 준비 불가 |
| **MCP Servers** | 등록된 활성 MCP 서버별 연결 확인 | 10초 | 해당 MCP 도구 사용 불가 |
| **Event Bus** | Publisher/Subscriber 연결 확인 (Redis ping 등) | 3초 | 이벤트 기반 실행 흐름 중단 |
| **File System** | WorkTree/Workflow 루트 디렉토리 쓰기 가능 여부 | 3초 | WorkTree/Report 생성 불가 |

### 4.5 헬스 체크 흐름

```mermaid
sequenceDiagram
    participant LB as Load Balancer
    participant APP as Application
    participant DB as Database
    participant GIT as Git CLI
    participant MCP as MCP Servers
    participant EB as Event Bus
    participant FS as File System

    LB->>APP: GET /ready
    par 병렬 체크
        APP->>DB: SELECT 1
        DB-->>APP: OK (12ms)
    and
        APP->>GIT: git --version
        GIT-->>APP: OK (45ms)
    and
        APP->>MCP: validate connections
        MCP-->>APP: OK (200ms)
    and
        APP->>EB: ping
        EB-->>APP: OK (3ms)
    and
        APP->>FS: write test file
        FS-->>APP: OK (5ms)
    end
    APP-->>LB: 200 OK (all checks passed)
```

---

## 5. 알림/알람 정책

### 5.1 알람 레벨 정의

| 레벨 | 기준 | 대응 시간 | 알림 채널 |
|------|------|----------|----------|
| **Critical** | 서비스 중단 또는 데이터 손실 위험 | 즉시 (5분 이내) | PagerDuty + Slack #critical + SMS |
| **Warning** | 성능 저하 또는 잠재적 장애 | 30분 이내 | Slack #warning + Email |
| **Info** | 운영 참고 사항 | 업무 시간 내 | Slack #info |

### 5.2 알람 규칙 상세

#### Critical 알람

| 알람명 | 조건 | 설명 |
|--------|------|------|
| `DatabaseDown` | /ready의 database 체크 실패 3회 연속 | DB 연결 불가 |
| `WorkflowFailureSpike` | 5분 간 `workflow.failed.total` > 3 | Workflow 연속 실패 |
| `AgentProcessCrash` | Agent 프로세스가 시작 후 10초 이내 종료 | Agent 환경 문제 |
| `DiskSpaceCritical` | WorkTree/Workflow 루트 여유 공간 < 5GB | 디스크 부족으로 서비스 장애 임박 |
| `EventBusDown` | 이벤트 발행 실패 5회 연속 | 이벤트 기반 실행 불가 |
| `GitClientFailure` | Git 명령 실행 실패율 > 50% (5분 간) | Git 연동 장애 |

#### Warning 알람

| 알람명 | 조건 | 설명 |
|--------|------|------|
| `HighEventLatency` | `event.processing.delay` p95 > 5초 | 이벤트 처리 지연 |
| `WorkTreeDiskHigh` | `worktree.disk.usage.bytes` > 50GB | WorkTree 디스크 사용량 높음 |
| `AgentSlowResponse` | `agent.response.duration` p95 > 5분 | Agent 응답 지연 |
| `McpConnectionFlaky` | MCP 연결 검증 실패 > 3회 (10분 간) | MCP 서버 불안정 |
| `HighQueueDepth` | `event.queue.depth` > 100 | 이벤트 큐 적체 |
| `DBConnectionPoolHigh` | 활성 커넥션 > pool_size * 0.8 | 커넥션 풀 고갈 위험 |
| `DiskSpaceWarning` | 여유 공간 < 20GB | 디스크 공간 부족 예고 |
| `WorkflowSuccessRateLow` | `workflow.success.rate` < 80% | Workflow 성공률 저하 |

#### Info 알람

| 알람명 | 조건 | 설명 |
|--------|------|------|
| `WorkflowCompleted` | Workflow 정상 완료 | 실행 완료 알림 |
| `CheckpointStale` | 무효화된 Checkpoint > 200 | 정리 필요 |
| `ReportStorageGrowing` | Report 파일 > 1000개 | 아카이브 고려 |
| `HighConcurrentWorkflows` | 동시 실행 Workflow > 10 | 리소스 사용 증가 |

### 5.3 알림 흐름

```mermaid
graph TB
    PROM[Prometheus] -->|alert rules| AM[Alertmanager]

    AM -->|Critical| PD[PagerDuty]
    AM -->|Critical| SC[Slack #critical]
    AM -->|Critical| SMS[SMS]

    AM -->|Warning| SW[Slack #warning]
    AM -->|Warning| EMAIL[Email]

    AM -->|Info| SI[Slack #info]

    AM -->|grouping| AM
    AM -->|silencing| AM
    AM -->|inhibition| AM
```

**Alertmanager 정책**
- **Grouping**: 동일 Workflow에서 발생한 알람은 그룹화
- **Inhibition**: Critical 알람 발생 시 동일 카테고리의 Warning 알람 억제
- **Silencing**: 계획된 배포/점검 시 일시적으로 알람 무음 처리

---

## 6. 배포 전략

### 6.1 Docker 컨테이너화

**Multi-stage Build Dockerfile**

```dockerfile
# Stage 1: Build
FROM node:20-alpine AS builder
WORKDIR /app
COPY package*.json ./
RUN npm ci --production=false
COPY . .
RUN npm run build
RUN npm prune --production

# Stage 2: Production
FROM node:20-alpine AS production
RUN apk add --no-cache git

WORKDIR /app
COPY --from=builder /app/dist ./dist
COPY --from=builder /app/node_modules ./node_modules
COPY --from=builder /app/package.json ./

ENV NODE_ENV=production
EXPOSE 3000

HEALTHCHECK --interval=30s --timeout=5s --retries=3 \
  CMD wget -qO- http://localhost:3000/health || exit 1

USER node
CMD ["node", "dist/main.js"]
```

**핵심 고려사항**
- Git CLI가 컨테이너 내에 설치되어야 함 (`apk add git`)
- WorkTree/Workflow 데이터 디렉토리는 외부 볼륨으로 마운트
- non-root 사용자(`node`)로 실행

### 6.2 환경 분리

```mermaid
graph LR
    subgraph "Development"
        DEV_APP[App] --> DEV_DB[(SQLite)]
        DEV_APP --> DEV_EB[In-Memory EventBus]
    end

    subgraph "Staging"
        STG_APP[App] --> STG_DB[(PostgreSQL)]
        STG_APP --> STG_EB[Redis EventBus]
        STG_APP --> STG_MCP[MCP Servers]
    end

    subgraph "Production"
        PRD_APP[App] --> PRD_DB[(PostgreSQL HA)]
        PRD_APP --> PRD_EB[Redis Cluster EventBus]
        PRD_APP --> PRD_MCP[MCP Servers]
        PRD_APP --> PRD_MON[Prometheus + Grafana]
    end
```

| 환경 | DB | Event Bus | 로그 레벨 | 모니터링 | 비고 |
|------|-----|-----------|----------|---------|------|
| **dev** | SQLite / In-Memory | In-Memory EventEmitter | DEBUG | 없음 | 로컬 개발 |
| **staging** | PostgreSQL | Redis Pub/Sub | INFO | Prometheus + Grafana | 프로덕션 미러 |
| **prod** | PostgreSQL (HA) | Redis Cluster | INFO | Full stack (Prometheus, Grafana, Loki, Tempo) | 고가용성 |

### 6.3 CI/CD 파이프라인

```mermaid
graph LR
    A[Git Push] --> B[Lint + Type Check]
    B --> C[Unit Test]
    C --> D[Integration Test]
    D --> E[Build Docker Image]
    E --> F[Image Scan]
    F --> G{Branch?}
    G -->|main| H[Deploy Staging]
    G -->|release/*| I[Deploy Production]
    H --> J[E2E Test on Staging]
    J --> K[Promote to Production]
    I --> L[Canary Deploy]
    L --> M[Full Rollout]
```

**파이프라인 단계 상세**

| 단계 | 도구 | 설명 | 실패 시 |
|------|------|------|--------|
| Lint + Type Check | ESLint + TSC | 코드 품질 및 타입 검증 | 파이프라인 중단 |
| Unit Test | Jest/Vitest | 도메인 로직, UseCase 단위 테스트 | 파이프라인 중단 |
| Integration Test | Testcontainers | DB, Git, EventBus 통합 테스트 | 파이프라인 중단 |
| Build Docker Image | Docker Buildx | Multi-stage 이미지 빌드 | 파이프라인 중단 |
| Image Scan | Trivy | 보안 취약점 스캔 | Critical 발견 시 중단 |
| Deploy Staging | Kubernetes/Docker Compose | Staging 환경 배포 | 파이프라인 중단 |
| E2E Test | Playwright/Cypress | 전체 흐름 검증 | Staging 롤백 |
| Deploy Production | Kubernetes | Rolling update 또는 Canary | 자동 롤백 |

### 6.4 무중단 배포 (Graceful Shutdown)

실행 중인 Workflow를 보호하면서 배포한다.

```mermaid
sequenceDiagram
    participant K8S as Kubernetes
    participant OLD as Old Pod
    participant NEW as New Pod
    participant WF as Running Workflows

    K8S->>NEW: 새 Pod 생성
    NEW->>NEW: /ready 대기
    NEW-->>K8S: Ready

    K8S->>OLD: SIGTERM 전송
    OLD->>OLD: Graceful shutdown 시작

    Note over OLD: 1. 새 요청 수신 중단
    Note over OLD: 2. /ready → 503 반환
    Note over OLD: 3. 실행 중 Workflow Pause

    OLD->>WF: PauseWorkflowUseCase (실행 중인 Work)
    WF-->>OLD: Agent 중지, 상태 저장

    Note over OLD: 4. 진행 중 이벤트 처리 완료 대기
    Note over OLD: 5. DB 커넥션 풀 drain

    OLD-->>K8S: 종료 완료

    Note over NEW: 재기동 후 PAUSED Workflow는<br/>수동 또는 자동 Resume 가능
```

**Graceful Shutdown 절차**

1. **SIGTERM 수신**: 새로운 HTTP 요청 수신 중단
2. **Readiness 비활성화**: `/ready` 엔드포인트가 503 반환
3. **실행 중 Workflow 보호**:
   - RUNNING 상태 Workflow를 `PauseWorkflowUseCase`로 일시정지
   - 현재 실행 중인 Agent 프로세스에 graceful stop 신호 전송
   - Work 상태를 PAUSED로 저장
4. **이벤트 처리 완료**: 진행 중인 이벤트 핸들러가 완료될 때까지 대기 (최대 `SHUTDOWN_TIMEOUT`)
5. **리소스 정리**: DB 커넥션 풀, Redis 연결 등 해제
6. **프로세스 종료**

```typescript
// Graceful shutdown 설정
const SHUTDOWN_CONFIG = {
  shutdownTimeout: 60_000,      // 전체 종료 타임아웃 (ms)
  agentStopTimeout: 30_000,     // Agent 중지 대기 시간 (ms)
  eventDrainTimeout: 15_000,    // 이벤트 처리 완료 대기 (ms)
  connectionDrainTimeout: 5_000 // 커넥션 drain 대기 (ms)
};
```

---

## 7. 리소스 정리 정책

### 7.1 WorkTree 자동 정리

완료 또는 취소된 Workflow의 WorkTree를 TTL(Time To Live) 기반으로 자동 정리한다.

| 정책 | 조건 | TTL | 동작 |
|------|------|-----|------|
| **즉시 정리** | Workflow 삭제 (DeleteWorkflowUseCase) | 0 | `cleanupResources()`로 WorkTree + WorkSpace 즉시 삭제 |
| **지연 정리** | Workflow COMPLETED/CANCELLED 상태 전이 후 | 24시간 (설정 가능) | 스케줄러가 주기적으로 만료된 WorkTree 정리 |
| **강제 정리** | 디스크 사용량 임계값 초과 시 | 0 | 가장 오래된 완료/취소 Workflow의 WorkTree부터 삭제 |

```mermaid
graph TB
    SCHED[Cleanup Scheduler<br/>매 1시간 실행] --> CHECK{만료된<br/>WorkTree 존재?}
    CHECK -->|Yes| FIND[COMPLETED/CANCELLED<br/>Workflow 조회]
    FIND --> FILTER[TTL 초과 필터링]
    FILTER --> DELETE[WorkTree 삭제<br/>+ branch 삭제]
    DELETE --> LOG[정리 결과 로깅]
    CHECK -->|No| DISK{디스크 사용량<br/>> 임계값?}
    DISK -->|Yes| FORCE[강제 정리<br/>가장 오래된 순]
    DISK -->|No| END[대기]
```

### 7.2 Report 파일 보존/아카이브 정책

| 단계 | 조건 | 동작 |
|------|------|------|
| **활성 보존** | Workflow RUNNING/PAUSED 상태 | 원본 파일 유지, WorkSpace symlink 활성 |
| **완료 보존** | Workflow COMPLETED 후 7일 이내 | 원본 파일 유지, 조회 가능 |
| **아카이브** | Workflow COMPLETED 후 7~30일 | 압축 아카이브(tar.gz)로 이동 |
| **삭제** | Workflow COMPLETED 후 30일 초과 또는 Workflow 삭제 시 | 아카이브 파일 삭제 |

```
/workflows/{workflowId}/reports/          # 활성/완료 보존
/archive/reports/{workflowId}.tar.gz      # 아카이브
```

### 7.3 무효화된 Checkpoint 데이터 정리

Checkpoint는 Work 순서 변경 시 `workSequence` 불일치로 자동 무효화된다. 무효화된 Checkpoint는 이력 보존 목적으로 즉시 삭제하지 않으나, 주기적으로 정리한다.

| 조건 | 동작 |
|------|------|
| 무효화 후 7일 경과 | 스케줄러가 삭제 |
| Workflow 삭제 시 | `deleteByWorkflowId()`로 일괄 삭제 |
| 무효화된 Checkpoint > 200개 | Info 알림 발생 후 스케줄러 즉시 실행 |

### 7.4 디스크 용량 모니터링 및 알람

```mermaid
graph TB
    MON[디스크 모니터링<br/>매 5분 실행] --> CHECK_WT[WorkTree 루트<br/>사용량 측정]
    MON --> CHECK_WF[Workflow 루트<br/>사용량 측정]
    MON --> CHECK_FREE[전체 여유 공간<br/>확인]

    CHECK_WT --> WT_METRIC[worktree.disk.usage.bytes<br/>메트릭 갱신]
    CHECK_WF --> WF_METRIC[report.disk.usage.bytes<br/>메트릭 갱신]

    CHECK_FREE --> EVAL{여유 공간}
    EVAL -->|< 5GB| CRIT[Critical 알람<br/>+ 강제 정리 트리거]
    EVAL -->|< 20GB| WARN[Warning 알람]
    EVAL -->|>= 20GB| OK[정상]
```

**디스크 사용 위치 요약**

| 경로 | 내용 | 증가 요인 | 정리 주체 |
|------|------|----------|----------|
| `/worktrees/` | Git worktree 디렉토리 | Workflow 생성, Git 리포지토리 크기 | WorkTree 정리 스케줄러 |
| `/workflows/*/reports/` | Report 마크다운 파일 | Task 완료 시 Report 생성 | Report 아카이브 스케줄러 |
| `/archive/` | 아카이브된 Report | 아카이브 정책에 의한 이동 | 보존 기한 후 삭제 |
| DB storage | Aggregate, Checkpoint 등 | 전체 사용에 비례 | Checkpoint 정리, Workflow 삭제 |

---

## 8. 설정 관리

### 8.1 환경 변수 목록

#### 애플리케이션 기본 설정

| 환경 변수 | 기본값 | 필수 | 설명 |
|----------|--------|------|------|
| `NODE_ENV` | `development` | O | 실행 환경 (development, staging, production) |
| `PORT` | `3000` | X | HTTP 서버 포트 |
| `APP_VERSION` | — | X | 애플리케이션 버전 (Docker 빌드 시 주입) |
| `LOG_LEVEL` | `info` | X | 로그 레벨 (error, warn, info, debug) |
| `SHUTDOWN_TIMEOUT_MS` | `60000` | X | Graceful shutdown 타임아웃 (ms) |

#### Database 설정

| 환경 변수 | 기본값 | 필수 | 설명 |
|----------|--------|------|------|
| `DATABASE_URL` | — | O | DB 연결 문자열 (예: `postgresql://user:pass@host:5432/db`) |
| `DATABASE_POOL_MIN` | `2` | X | 커넥션 풀 최소 수 |
| `DATABASE_POOL_MAX` | `10` | X | 커넥션 풀 최대 수 |
| `DATABASE_CONNECTION_TIMEOUT_MS` | `5000` | X | 커넥션 획득 타임아웃 (ms) |

#### Git 설정

| 환경 변수 | 기본값 | 필수 | 설명 |
|----------|--------|------|------|
| `GIT_ROOT_PATH` | — | O | Git 리포지토리 클론 루트 디렉토리 |
| `WORKTREE_ROOT_PATH` | — | O | WorkTree 생성 루트 디렉토리 |
| `GIT_COMMAND_TIMEOUT_MS` | `120000` | X | Git 명령 실행 타임아웃 (ms) |
| `GIT_CLONE_DEPTH` | `0` (전체) | X | Git clone 깊이 (0이면 전체 히스토리) |

#### Workflow 설정

| 환경 변수 | 기본값 | 필수 | 설명 |
|----------|--------|------|------|
| `WORKFLOW_ROOT_PATH` | — | O | Workflow 파일시스템 작업 공간 루트 |
| `WORKFLOW_MAX_CONCURRENT` | `10` | X | 최대 동시 실행 Workflow 수 |
| `WORKTREE_CLEANUP_TTL_HOURS` | `24` | X | 완료/취소 후 WorkTree 보존 시간 |
| `REPORT_ARCHIVE_DAYS` | `7` | X | Report 완료 후 아카이브까지 보존 일수 |
| `REPORT_DELETE_DAYS` | `30` | X | Report 아카이브 후 삭제까지 보존 일수 |
| `CHECKPOINT_CLEANUP_DAYS` | `7` | X | 무효화된 Checkpoint 보존 일수 |

#### Agent 설정

| 환경 변수 | 기본값 | 필수 | 설명 |
|----------|--------|------|------|
| `AGENT_START_TIMEOUT_MS` | `30000` | X | Agent 프로세스 시작 타임아웃 (ms) |
| `AGENT_QUERY_TIMEOUT_MS` | `600000` | X | Agent Query 응답 타임아웃 (ms, 기본 10분) |
| `AGENT_STOP_TIMEOUT_MS` | `30000` | X | Agent graceful stop 타임아웃 (ms) |
| `AGENT_MAX_CONCURRENT` | `20` | X | 최대 동시 실행 Agent 프로세스 수 |

#### Event Bus 설정

| 환경 변수 | 기본값 | 필수 | 설명 |
|----------|--------|------|------|
| `EVENT_BUS_TYPE` | `in-memory` | X | 이벤트 버스 유형 (in-memory, redis) |
| `REDIS_URL` | — | 조건부 | Redis 연결 URL (EVENT_BUS_TYPE=redis일 때 필수) |
| `EVENT_RETRY_MAX_ATTEMPTS` | `3` | X | 이벤트 처리 최대 재시도 횟수 |
| `EVENT_RETRY_DELAY_MS` | `1000` | X | 이벤트 재시도 대기 시간 (ms) |

#### MCP 설정

| 환경 변수 | 기본값 | 필수 | 설명 |
|----------|--------|------|------|
| `MCP_VALIDATION_TIMEOUT_MS` | `10000` | X | MCP 서버 연결 검증 타임아웃 (ms) |
| `MCP_MAX_SERVERS` | `50` | X | 최대 등록 가능 MCP 서버 수 |

#### 모니터링 설정

| 환경 변수 | 기본값 | 필수 | 설명 |
|----------|--------|------|------|
| `OTEL_EXPORTER_OTLP_ENDPOINT` | — | 조건부 | OpenTelemetry Collector 엔드포인트 (트레이싱 사용 시 필수) |
| `OTEL_ENABLED` | `false` | X | OpenTelemetry 활성화 여부 |
| `METRICS_ENABLED` | `true` | X | Prometheus 메트릭 노출 활성화 |
| `METRICS_PATH` | `/metrics` | X | 메트릭 엔드포인트 경로 |
| `HEALTH_CHECK_INTERVAL_MS` | `30000` | X | 외부 의존성 헬스 체크 주기 (ms) |

#### 디스크 정리 설정

| 환경 변수 | 기본값 | 필수 | 설명 |
|----------|--------|------|------|
| `CLEANUP_SCHEDULE_CRON` | `0 * * * *` | X | 정리 스케줄러 cron 표현식 (기본: 매 시) |
| `DISK_WARNING_THRESHOLD_GB` | `20` | X | 디스크 Warning 알람 임계값 (GB) |
| `DISK_CRITICAL_THRESHOLD_GB` | `5` | X | 디스크 Critical 알람 임계값 (GB) |
| `ARCHIVE_ROOT_PATH` | — | X | Report 아카이브 저장 경로 (미설정 시 WORKFLOW_ROOT_PATH/archive) |

### 8.2 환경별 설정 예시

**Development (.env.development)**
```env
NODE_ENV=development
PORT=3000
LOG_LEVEL=debug
DATABASE_URL=file:./dev.db
GIT_ROOT_PATH=./data/git
WORKTREE_ROOT_PATH=./data/worktrees
WORKFLOW_ROOT_PATH=./data/workflows
EVENT_BUS_TYPE=in-memory
OTEL_ENABLED=false
```

**Production (.env.production)**
```env
NODE_ENV=production
PORT=3000
LOG_LEVEL=info
DATABASE_URL=postgresql://user:${DB_PASSWORD}@db-host:5432/workflow_engine
DATABASE_POOL_MAX=20
GIT_ROOT_PATH=/data/git
WORKTREE_ROOT_PATH=/data/worktrees
WORKFLOW_ROOT_PATH=/data/workflows
EVENT_BUS_TYPE=redis
REDIS_URL=redis://:${REDIS_PASSWORD}@redis-host:6379
OTEL_ENABLED=true
OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4318
WORKFLOW_MAX_CONCURRENT=10
AGENT_MAX_CONCURRENT=20
```

---

## 관련 문서
- [01-서비스-개요.md](01-서비스-개요.md) — 시스템 전체 아키텍처 및 외부 의존성
- [02-도메인-모델.md](02-도메인-모델.md) — Aggregate 상세 및 상태 정의
- [04-이벤트-흐름.md](04-이벤트-흐름.md) — 이벤트 카탈로그 및 핸들러 매핑
- [05-인프라스트럭처.md](05-인프라스트럭처.md) — Port/Adapter 및 리소스 관리 전략
